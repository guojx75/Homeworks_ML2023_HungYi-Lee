{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":48952,"databundleVersionId":5186467,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:14.752594Z","iopub.execute_input":"2025-12-03T05:50:14.752849Z","iopub.status.idle":"2025-12-03T05:50:14.974714Z","shell.execute_reply.started":"2025-12-03T05:50:14.752831Z","shell.execute_reply":"2025-12-03T05:50:14.973872Z"}},"outputs":[{"name":"stdout","text":"Wed Dec  3 05:50:14 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport random\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\nfrom torchvision import models\nfrom tqdm.auto import tqdm\nimport random\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:14.976628Z","iopub.execute_input":"2025-12-03T05:50:14.976902Z","iopub.status.idle":"2025-12-03T05:50:22.901699Z","shell.execute_reply.started":"2025-12-03T05:50:14.976881Z","shell.execute_reply":"2025-12-03T05:50:22.901134Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"myseed = 6666\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)\n\n_exp_name = \"sample\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:22.902406Z","iopub.execute_input":"2025-12-03T05:50:22.902790Z","iopub.status.idle":"2025-12-03T05:50:22.993554Z","shell.execute_reply.started":"2025-12-03T05:50:22.902761Z","shell.execute_reply":"2025-12-03T05:50:22.992994Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# However, it is also possible to use augmentation in the testing phase.\n# You may use train_tfm to produce a variety of images and then test using ensemble methods\ntrain_tfm = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    # transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n \n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.55807906, 0.45261728, 0.34557677], std=[0.23075283, 0.24137004, 0.24039967])\n])\n \n# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    # transforms.Resize((128, 128)),\n    transforms.Resize(256),  # 256\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.55807906, 0.45261728, 0.34557677], std=[0.23075283, 0.24137004, 0.24039967])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:22.994356Z","iopub.execute_input":"2025-12-03T05:50:22.994543Z","iopub.status.idle":"2025-12-03T05:50:22.999621Z","shell.execute_reply.started":"2025-12-03T05:50:22.994528Z","shell.execute_reply":"2025-12-03T05:50:22.998740Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class FoodDataset(Dataset):\n    def __init__(self, path, tfm=test_tfm, files=None):\n        super().__init__()\n        self.path = path\n        # 读取目录下所有 jpg 文件\n        self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files != None:\n            self.files = files\n        self.transform = tfm\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        \n        try:\n            # 解析文件名获取标签\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # 测试集没有标签\n            \n        return im, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:23.001557Z","iopub.execute_input":"2025-12-03T05:50:23.001765Z","iopub.status.idle":"2025-12-03T05:50:23.014353Z","shell.execute_reply.started":"2025-12-03T05:50:23.001750Z","shell.execute_reply":"2025-12-03T05:50:23.013617Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # 使用 torchvision 的 resnet18\n        self.backbone = models.resnet18(pretrained=True)\n        # 替换最后一层，全连接输出 11 类\n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Linear(in_features, 11)\n\n    def forward(self, x):\n        return self.backbone(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:23.015049Z","iopub.execute_input":"2025-12-03T05:50:23.015363Z","iopub.status.idle":"2025-12-03T05:50:23.029761Z","shell.execute_reply.started":"2025-12-03T05:50:23.015346Z","shell.execute_reply":"2025-12-03T05:50:23.029038Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# 初始化模型\nmodel = Classifier().to(device)\n\n# --- 优化部分：双卡并行 ---\nif torch.cuda.device_count() > 1:\n    print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\n\n# 超参数设置\n# 优化：增大 batch_size 以利用双卡显存 (64 -> 128)\nbatch_size = 128 \n\n# 优化：增加训练轮数 (8 -> 60)\nn_epochs = 20 \n\n# 优化：增加早停耐心值 (5 -> 15)\npatience = 5 \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n\ntrain_path = '/kaggle/input/ml2023spring-hw3/train'\nvalid_path = '/kaggle/input/ml2023spring-hw3/valid'\ntest_path = '/kaggle/input/ml2023spring-hw3/test'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:23.030418Z","iopub.execute_input":"2025-12-03T05:50:23.030661Z","iopub.status.idle":"2025-12-03T05:50:23.837736Z","shell.execute_reply.started":"2025-12-03T05:50:23.030636Z","shell.execute_reply":"2025-12-03T05:50:23.837073Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 173MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_set = FoodDataset(train_path, tfm=train_tfm)\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n\nvalid_set = FoodDataset(valid_path, tfm=test_tfm)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n\nprint('data ok')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:23.838583Z","iopub.execute_input":"2025-12-03T05:50:23.838813Z","iopub.status.idle":"2025-12-03T05:50:23.998116Z","shell.execute_reply.started":"2025-12-03T05:50:23.838795Z","shell.execute_reply":"2025-12-03T05:50:23.997543Z"}},"outputs":[{"name":"stdout","text":"data ok\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"stale = 0\nbest_acc = 0\n\nfor epoch in range(n_epochs):\n    # ---------- Training ----------\n    model.train()\n    train_loss = []\n    train_accs = []\n\n    for batch in tqdm(train_loader):\n        imgs, labels = batch\n        logits = model(imgs.to(device))\n        loss = criterion(logits, labels.to(device))\n        optimizer.zero_grad()\n        loss.backward()\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n        optimizer.step()\n\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n\n    train_loss = sum(train_loss) / len(train_loss)\n    train_acc = sum(train_accs) / len(train_accs)\n    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n\n    # ---------- Validation ----------\n    model.eval()\n    valid_loss = []\n    valid_accs = []\n\n    for batch in tqdm(valid_loader):\n        imgs, labels = batch\n        with torch.no_grad():\n            logits = model(imgs.to(device))\n        loss = criterion(logits, labels.to(device))\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n\n    valid_loss = sum(valid_loss) / len(valid_loss)\n    valid_acc = sum(valid_accs) / len(valid_accs)\n    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n    # 更新日志\n    if valid_acc > best_acc:\n        with open(f\"./{_exp_name}_log.txt\",\"a\") as f:\n            f.write(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\\n\")\n    else:\n        with open(f\"./{_exp_name}_log.txt\",\"a\") as f:\n            f.write(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\\n\")\n\n    # 保存模型 - 优化：处理 DataParallel 的保存\n    if valid_acc > best_acc:\n        print(f\"Best model found at epoch {epoch + 1}, saving model\")\n        # 如果使用了 DataParallel，需要保存 model.module 的参数\n        if isinstance(model, nn.DataParallel):\n            torch.save(model.module.state_dict(), f\"{_exp_name}_best.ckpt\")\n        else:\n            torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\")\n        best_acc = valid_acc\n        stale = 0\n    else:\n        stale += 1\n        if stale > patience:\n            print(f\"No improvement {patience} consecutive epochs, early stopping\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:50:23.998877Z","iopub.execute_input":"2025-12-03T05:50:23.999160Z","iopub.status.idle":"2025-12-03T06:02:22.192301Z","shell.execute_reply.started":"2025-12-03T05:50:23.999143Z","shell.execute_reply":"2025-12-03T06:02:22.191410Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ede34859cd4c5e83ae26d3074e0899"}},"metadata":{}},{"name":"stdout","text":"[ Train | 001/020 ] loss = 0.83918, acc = 0.72844\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b1c920e220491eb62b441c3778cca4"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 001/020 ] loss = 0.55892, acc = 0.80872\nBest model found at epoch 1, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da51bad741994c79add6d79e0ad3e7ca"}},"metadata":{}},{"name":"stdout","text":"[ Train | 002/020 ] loss = 0.54986, acc = 0.82189\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d223e3d2947b49a1907be8944f773a5c"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 002/020 ] loss = 0.51082, acc = 0.83436\nBest model found at epoch 2, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dacc23a1af1943c18efd9e73011aa11a"}},"metadata":{}},{"name":"stdout","text":"[ Train | 003/020 ] loss = 0.46915, acc = 0.85057\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"551e402e56f54a8b90c06ec7a9d3df21"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 003/020 ] loss = 0.47206, acc = 0.85066\nBest model found at epoch 3, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e6bebfccdd4d6ab4ad49b6fc7b4198"}},"metadata":{}},{"name":"stdout","text":"[ Train | 004/020 ] loss = 0.43078, acc = 0.86027\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6faf32b7cba4396a4fefb1e67dae3d4"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 004/020 ] loss = 0.48695, acc = 0.84635\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7499b0e52f4d27b229c952142200bb"}},"metadata":{}},{"name":"stdout","text":"[ Train | 005/020 ] loss = 0.40633, acc = 0.87085\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94a8d6f8a8c64c8ba1dd2c9acc61aa11"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 005/020 ] loss = 0.39079, acc = 0.88178\nBest model found at epoch 5, saving model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5ff256f603c4564b8b2c8c3476005f2"}},"metadata":{}},{"name":"stdout","text":"[ Train | 006/020 ] loss = 0.36105, acc = 0.88172\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b8ef8a09dd743a1bc37be12257b782e"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 006/020 ] loss = 0.42547, acc = 0.86489\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4153aaafb7b9450394560c68f201ea3d"}},"metadata":{}},{"name":"stdout","text":"[ Train | 007/020 ] loss = 0.34538, acc = 0.88489\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1565d36b1b494bfd91335372cfc86e92"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 007/020 ] loss = 0.43959, acc = 0.86485\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec0db7368324dda84aa8e31b54f8de2"}},"metadata":{}},{"name":"stdout","text":"[ Train | 008/020 ] loss = 0.31013, acc = 0.89765\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc3e7fb7df649a19647fce97d3dbe77"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 008/020 ] loss = 0.43062, acc = 0.86606\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62f92bed01904718a047ab5e81c6c9b6"}},"metadata":{}},{"name":"stdout","text":"[ Train | 009/020 ] loss = 0.32234, acc = 0.89587\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d90f8da9a4f440cb0ea67a44e7e3e3c"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 009/020 ] loss = 0.40381, acc = 0.87634\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ab79ef317d94e54841ff5f7d85c8a57"}},"metadata":{}},{"name":"stdout","text":"[ Train | 010/020 ] loss = 0.29269, acc = 0.90457\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e51a51506724ca3b878457c0d044500"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 010/020 ] loss = 0.41331, acc = 0.86893\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be68cff1cb36499098f3802ea74a1bfc"}},"metadata":{}},{"name":"stdout","text":"[ Train | 011/020 ] loss = 0.29676, acc = 0.90398\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d04a46aecc466dbf832b262e8b8a0d"}},"metadata":{}},{"name":"stdout","text":"[ Valid | 011/020 ] loss = 0.41382, acc = 0.87742\nNo improvement 5 consecutive epochs, early stopping\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"test_set = FoodDataset(test_path, tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n# 加载最佳模型\nmodel_best = Classifier().to(device)\nmodel_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\nmodel_best.eval()\n\nprediction = []\nwith torch.no_grad():\n    for data, _ in tqdm(test_loader):\n        test_pred = model_best(data.to(device))\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n        prediction += test_label.squeeze().tolist()\n\n# 创建提交文件\ndef pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\n    \ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(len(test_set))]\ndf[\"Category\"] = prediction\ndf.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file saved as submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:02:22.193856Z","iopub.execute_input":"2025-12-03T06:02:22.194151Z","iopub.status.idle":"2025-12-03T06:02:38.304296Z","shell.execute_reply.started":"2025-12-03T06:02:22.194119Z","shell.execute_reply":"2025-12-03T06:02:38.303520Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/24 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8231082c74184ff49d90b9587982fea7"}},"metadata":{}},{"name":"stdout","text":"Submission file saved as submission.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# 加载训练好的模型\nmodel = Classifier().to(device)\nstate_dict = torch.load(f\"{_exp_name}_best.ckpt\", map_location=device)\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\n# 定义一个函数：获取 resnet 的 fc 之前的特征\ndef extract_features_backbone(x):\n    # 参考 torchvision.models.resnet18 的 forward 源码\n    x = model.backbone.conv1(x)\n    x = model.backbone.bn1(x)\n    x = model.backbone.relu(x)\n    x = model.backbone.maxpool(x)\n\n    x = model.backbone.layer1(x)\n    x = model.backbone.layer2(x)\n    x = model.backbone.layer3(x)\n    x = model.backbone.layer4(x)\n\n    x = model.backbone.avgpool(x)          # (B, 512, 1, 1)\n    x = torch.flatten(x, 1)                # (B, 512)\n    return x\n\nvalid_set = FoodDataset(valid_path, tfm=test_tfm)\nvalid_loader = DataLoader(valid_set, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n\nfeatures = []\nlabels = []\n\nfor batch in tqdm(valid_loader):\n    imgs, lbls = batch\n    with torch.no_grad():\n        feats = extract_features_backbone(imgs.to(device))\n    labels.extend(lbls.cpu().numpy())\n    feats = feats.cpu().numpy()\n    features.extend(feats)\n\nfeatures = np.array(features)\nlabels = np.array(labels)\n\n# t-SNE 可视化\nfeatures_tsne = TSNE(n_components=2, init='pca', random_state=42).fit_transform(features)\nplt.figure(figsize=(10, 8))\nfor label in np.unique(labels):\n    plt.scatter(features_tsne[labels == label, 0], features_tsne[labels == label, 1], label=label, s=5)\nplt.legend()\nplt.title(\"t-SNE of ResNet18 Features\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:02:38.305954Z","iopub.execute_input":"2025-12-03T06:02:38.306344Z","execution_failed":"2025-12-03T06:04:58.463Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n100%|██████████| 57/57 [00:10<00:00,  5.49it/s]\n","output_type":"stream"}],"execution_count":null}]}